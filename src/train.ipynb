{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kunalkumarsahoo/Playground/Python/GrapHIV/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "No normalization for SPS. Feature removed!\n",
      "No normalization for AvgIpc. Feature removed!\n",
      "2024-09-15 00:17:03.118380: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-15 00:17:03.132235: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-15 00:17:03.136267: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-15 00:17:03.148655: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-15 00:17:04.034856: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kunalkumarsahoo/Playground/Python/GrapHIV/venv/lib/python3.10/site-packages/tensorflow/python/util/deprecation.py:588: calling function (from tensorflow.python.eager.polymorphic_function.polymorphic_function) with experimental_relax_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "experimental_relax_shapes is deprecated, use reduce_retracing instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. No module named 'torch.utils._import_utils'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Torch version: 2.2.1+cu121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kunalkumarsahoo/Playground/Python/GrapHIV/venv/lib/python3.10/site-packages/torch/cuda/__init__.py:628: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] CUDA availability: False\n",
      "[INFO] PyG version: 2.6.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.data import DataLoader\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, f1_score, accuracy_score, \n",
    "    precision_score, recall_score, roc_auc_score\n",
    ")\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from dataset import MoleculeDataset\n",
    "from model import MoleculeNet\n",
    "\n",
    "import mlflow.pytorch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device selected: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device selected:\", device)\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def train_one_epoch(epoch, model, train_loader, optimizer, loss_fn):\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    running_loss = 0.0\n",
    "    step = 0\n",
    "\n",
    "    for _, batch in enumerate(tqdm(train_loader)):\n",
    "        batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(batch.x.float(),\n",
    "                     batch.edge_attr.float(),\n",
    "                     batch.edge_index,\n",
    "                     batch.batch)\n",
    "        # Calculating the loss and gradients\n",
    "        loss = loss_fn(torch.squeeze(pred), batch.y.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Update tracking\n",
    "        running_loss += loss.item()\n",
    "        step += 1\n",
    "        all_preds.append(np.rint(torch.sigmoid(pred).cpu().detach().numpy()))\n",
    "        all_labels.append(batch.y.cpu().detach().numpy())\n",
    "    \n",
    "    all_preds = np.concatenate(all_preds).ravel()\n",
    "    all_labels = np.concatenate(all_labels).ravel()\n",
    "\n",
    "    calculate_metrics(all_preds, all_labels, epoch, \"train\")\n",
    "    return running_loss / step\n",
    "\n",
    "def test(epoch, model, test_loader, loss_fn):\n",
    "    all_preds = []\n",
    "    all_preds_raw = []\n",
    "    all_labels = []\n",
    "    running_loss = 0.0\n",
    "    step = 0\n",
    "    for batch in test_loader:\n",
    "        batch.to(device)  \n",
    "        pred = model(batch.x.float(), \n",
    "                        batch.edge_attr.float(),\n",
    "                        batch.edge_index, \n",
    "                        batch.batch) \n",
    "        loss = loss_fn(torch.squeeze(pred), batch.y.float())\n",
    "\n",
    "         # Update tracking\n",
    "        running_loss += loss.item()\n",
    "        step += 1\n",
    "        all_preds.append(np.rint(torch.sigmoid(pred).cpu().detach().numpy()))\n",
    "        all_preds_raw.append(torch.sigmoid(pred).cpu().detach().numpy())\n",
    "        all_labels.append(batch.y.cpu().detach().numpy())\n",
    "    \n",
    "    all_preds = np.concatenate(all_preds).ravel()\n",
    "    all_labels = np.concatenate(all_labels).ravel()\n",
    "    print(all_preds_raw[0][:10])\n",
    "    print(all_preds[:10])\n",
    "    print(all_labels[:10])\n",
    "    calculate_metrics(all_preds, all_labels, epoch, \"test\")\n",
    "    log_conf_matrix(all_preds, all_labels, epoch)\n",
    "    return running_loss/step\n",
    "\n",
    "def log_conf_matrix(y_pred, y_true, epoch):\n",
    "    # Log confusion matrix as image\n",
    "    cm = confusion_matrix(y_pred, y_true)\n",
    "    classes = [\"0\", \"1\"]\n",
    "    df_cfm = pd.DataFrame(cm, index = classes, columns = classes)\n",
    "    plt.figure(figsize = (10,7))\n",
    "    cfm_plot = sns.heatmap(df_cfm, annot=True, cmap='Blues', fmt='g')\n",
    "    cfm_plot.figure.savefig(f'../data/images/cm_{epoch}.png')\n",
    "    mlflow.log_artifact(f\"../data/images/cm_{epoch}.png\")\n",
    "\n",
    "def calculate_metrics(y_pred, y_true, epoch, type):\n",
    "    print(\"\\nConfusion matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
    "    print(\"\\nF1 score:\", f1_score(y_true, y_pred))\n",
    "    print(\"\\nAccuracy score:\", accuracy_score(y_true, y_pred))\n",
    "\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    print(f\"Precision score:\", precision)\n",
    "    print(f\"Recall score:\", recall)\n",
    "\n",
    "    mlflow.log_metric(key=f\"Precision-{type}\", value=float(precision), step=epoch)\n",
    "    mlflow.log_metric(key=f\"Recall-{type}\", value=float(recall), step=epoch)\n",
    "\n",
    "    try:\n",
    "        roc = roc_auc_score(y_true, y_pred)\n",
    "        print(\"ROC AUC:\", roc)\n",
    "        mlflow.log_metric(key=f\"ROC-AUC-{type}\", value=float(roc), step=epoch)\n",
    "    except:\n",
    "        mlflow.log_metric(key=f\"ROC-AUC-{type}\", value=0.0, step=epoch)\n",
    "        print(\"[Exception] ROC AUC: Not Defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mango import Tuner, scheduler\n",
    "from config import HYPERPARAMETERS, BEST_PARAMETERS, SIGNATURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_one_training(params):\n",
    "    params = params[0]\n",
    "    with mlflow.start_run() as run:\n",
    "        for key in params.keys():\n",
    "            mlflow.log_param(key, params[key])\n",
    "        \n",
    "        print(\"Loading dataset...\")\n",
    "        train_dataset = MoleculeDataset(root=\"../data/\", filename=\"HIV_train.csv\")\n",
    "        test_dataset = MoleculeDataset(root=\"../data/\", filename=\"HIV_test.csv\", test=True)\n",
    "        params[\"model_edge_dim\"] = train_dataset[0].edge_attr.shape[1]\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=params[\"batch_size\"], shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=params[\"batch_size\"], shuffle=True)\n",
    "\n",
    "        print(\"Loading model...\")\n",
    "        model_params = {k: v for k, v in params.items() if k.startswith(\"model_\")}\n",
    "        model = MoleculeNet(feature_size=train_dataset[0].x.shape[1], model_params=model_params)\n",
    "        model = model.to(device)\n",
    "        print(\"Number of parameters:\", count_parameters(model))\n",
    "        mlflow.log_param(\"num_params\", count_parameters(model))\n",
    "\n",
    "        # < 1 increases precision, > 1 recall\n",
    "        weight = torch.tensor([params[\"pos_weight\"]], dtype=torch.float32).to(device)\n",
    "        loss_fn = nn.BCEWithLogitsLoss(pos_weight=weight)\n",
    "        optimizer = optim.SGD(model.parameters(), lr=params[\"learning_rate\"], momentum=params[\"sgd_momentum\"], weight_decay=params[\"weight_decay\"])\n",
    "        scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=params[\"scheduler_gamma\"])\n",
    "\n",
    "        # Start training\n",
    "        best_loss = 1000\n",
    "        early_stopping_counter = 0\n",
    "        for epoch in range(300):\n",
    "            if early_stopping_counter <= 10:\n",
    "                # Training\n",
    "                model.train()\n",
    "                loss = train_one_epoch(epoch, model, train_loader, optimizer, loss_fn)\n",
    "                print(f\"Epoch {epoch} | Train loss: {loss}\")\n",
    "                mlflow.log_metric(key=\"Train loss\", value=float(loss), step=epoch)\n",
    "\n",
    "                # Validation\n",
    "                model.eval()\n",
    "                if epoch % 5 == 0:\n",
    "                    loss = test(epoch, model, test_loader, loss_fn)\n",
    "                    print(f\"Epoch {epoch} | Validation loss: {loss}\")\n",
    "                    mlflow.log_metric(key=\"Validation loss\", value=float(loss), step=epoch)\n",
    "\n",
    "                    if float(loss) < best_loss:\n",
    "                        best_loss = loss\n",
    "                        mlflow.pytorch.log_model(model, \"model\", signature=SIGNATURE)\n",
    "                        early_stopping_counter = 0\n",
    "                    else:\n",
    "                        early_stopping_counter += 1\n",
    "                \n",
    "                scheduler.step()\n",
    "\n",
    "            else:\n",
    "                print(\"Early stopping due to no improvement.\")\n",
    "                return [best_loss]\n",
    "    \n",
    "    print(\"Finishing training with best validation loss:\", best_loss)\n",
    "    return [best_loss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Hyperparameter search: \n",
      "Loading dataset...\n",
      "Loading model...\n",
      "Number of parameters: 314465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 497/497 [01:29<00:00,  5.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion matrix:\n",
      " [[ 5968 25787]\n",
      " [ 5519 26236]]\n",
      "\n",
      "F1 score: 0.6263219460956337\n",
      "\n",
      "Accuracy score: 0.5070697527948355\n",
      "Precision score: 0.5043153989581531\n",
      "Recall score: 0.8262005983309715\n",
      "ROC AUC: 0.5070697527948355\n",
      "Epoch 0 | Train loss: 0.6965196919393252\n",
      "[[0.49556014]\n",
      " [0.5101417 ]\n",
      " [0.49957067]\n",
      " [0.5120769 ]\n",
      " [0.51504093]\n",
      " [0.48992765]\n",
      " [0.51254153]\n",
      " [0.5105129 ]\n",
      " [0.52010846]\n",
      " [0.5136032 ]]\n",
      "[0. 1. 0. 1. 1. 0. 1. 1. 1. 1.]\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "Confusion matrix:\n",
      " [[1709 6220]\n",
      " [  30  267]]\n",
      "\n",
      "F1 score: 0.07871462264150944\n",
      "\n",
      "Accuracy score: 0.24021395575006077\n",
      "Precision score: 0.041159241560043164\n",
      "Recall score: 0.898989898989899\n",
      "ROC AUC: 0.5572638989211067\n",
      "Epoch 0 | Validation loss: 0.7105811421687787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 497/497 [01:31<00:00,  5.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion matrix:\n",
      " [[ 7548 24207]\n",
      " [ 6660 25095]]\n",
      "\n",
      "F1 score: 0.6191939005884748\n",
      "\n",
      "Accuracy score: 0.513982050070855\n",
      "Precision score: 0.5090057198490934\n",
      "Recall score: 0.7902692489371752\n",
      "ROC AUC: 0.513982050070855\n",
      "Epoch 1 | Train loss: 0.6891971581898465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 497/497 [01:31<00:00,  5.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion matrix:\n",
      " [[ 9041 22714]\n",
      " [ 7880 23875]]\n",
      "\n",
      "F1 score: 0.6094914735014807\n",
      "\n",
      "Accuracy score: 0.51828058573453\n",
      "Precision score: 0.5124600227521517\n",
      "Recall score: 0.7518501023460872\n",
      "ROC AUC: 0.51828058573453\n",
      "Epoch 2 | Train loss: 0.6857777769177013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|â–ˆâ–ˆâ–       | 123/497 [00:23<01:10,  5.30it/s]\n",
      "2024/09/15 00:22:18 INFO mlflow.tracking._tracking_service.client: ðŸƒ View run casual-newt-792 at: http://localhost:5000/#/experiments/0/runs/4a40e168d03b4feaa1ecd9fd23ec5d83.\n",
      "2024/09/15 00:22:18 INFO mlflow.tracking._tracking_service.client: ðŸ§ª View experiment at: http://localhost:5000/#/experiments/0.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_iteration\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m      6\u001b[0m tuner \u001b[38;5;241m=\u001b[39m Tuner(HYPERPARAMETERS, objective\u001b[38;5;241m=\u001b[39mrun_one_training, conf_dict\u001b[38;5;241m=\u001b[39mconfig)\n\u001b[0;32m----> 7\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Playground/Python/GrapHIV/mango/mango/tuner.py:127\u001b[0m, in \u001b[0;36mTuner.minimize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mminimize\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaximize_objective \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Playground/Python/GrapHIV/mango/mango/tuner.py:114\u001b[0m, in \u001b[0;36mTuner.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_bayesian:\n\u001b[0;32m--> 114\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunBayesianOptimizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_random:\n\u001b[1;32m    116\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunRandomOptimizer()\n",
      "File \u001b[0;32m~/Playground/Python/GrapHIV/mango/mango/tuner.py:176\u001b[0m, in \u001b[0;36mTuner.runBayesianOptimizer\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrunBayesianOptimizer\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    174\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[0;32m--> 176\u001b[0m     X_list, Y_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_initial\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;66;03m# evaluated hyperparameters are used\u001b[39;00m\n\u001b[1;32m    179\u001b[0m     X_init \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mds\u001b[38;5;241m.\u001b[39mconvert_GP_space(X_list)\n",
      "File \u001b[0;32m~/Playground/Python/GrapHIV/mango/mango/tuner.py:154\u001b[0m, in \u001b[0;36mTuner.run_initial\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# getting first few random values\u001b[39;00m\n\u001b[1;32m    153\u001b[0m     X_init \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mds\u001b[38;5;241m.\u001b[39mget_random_sample(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39minitial_random)\n\u001b[0;32m--> 154\u001b[0m     X_list, Y_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunUserObjective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_init\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;66;03m# in case initial random results are invalid try different samples\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     n_tries \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/Playground/Python/GrapHIV/mango/mango/tuner.py:342\u001b[0m, in \u001b[0;36mTuner.runUserObjective\u001b[0;34m(self, X_next_PS)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrunUserObjective\u001b[39m(\u001b[38;5;28mself\u001b[39m, X_next_PS):\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;66;03m# initially assuming entire X_next_PS is evaluated and returned results are only Y values\u001b[39;00m\n\u001b[1;32m    341\u001b[0m     X_list_evaluated \u001b[38;5;241m=\u001b[39m X_next_PS\n\u001b[0;32m--> 342\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobjective_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_next_PS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    343\u001b[0m     Y_list_evaluated \u001b[38;5;241m=\u001b[39m results\n\u001b[1;32m    345\u001b[0m     \u001b[38;5;66;03m# if result is a tuple, then there is possibility that partial values are evaluated\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[5], line 35\u001b[0m, in \u001b[0;36mrun_one_training\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m early_stopping_counter \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m:\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;66;03m# Training\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m---> 35\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Train loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     37\u001b[0m     mlflow\u001b[38;5;241m.\u001b[39mlog_metric(key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m(loss), step\u001b[38;5;241m=\u001b[39mepoch)\n",
      "Cell \u001b[0;32mIn[3], line 10\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(epoch, model, train_loader, optimizer, loss_fn)\u001b[0m\n\u001b[1;32m      7\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m      8\u001b[0m step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(train_loader)):\n\u001b[1;32m     11\u001b[0m     batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     12\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/Playground/Python/GrapHIV/venv/lib/python3.10/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/Playground/Python/GrapHIV/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/Playground/Python/GrapHIV/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/Playground/Python/GrapHIV/venv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/Playground/Python/GrapHIV/venv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/Playground/Python/GrapHIV/venv/lib/python3.10/site-packages/torch_geometric/data/dataset.py:291\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"In case :obj:`idx` is of type integer, will return the data object\u001b[39;00m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;124;03mat index :obj:`idx` (and transforms it in case :obj:`transform` is\u001b[39;00m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;124;03mpresent).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;124;03mbool, will return a subset of the dataset at the specified indices.\u001b[39;00m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(idx, (\u001b[38;5;28mint\u001b[39m, np\u001b[38;5;241m.\u001b[39minteger))\n\u001b[1;32m    288\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(idx, Tensor) \u001b[38;5;129;01mand\u001b[39;00m idx\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    289\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(idx, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(idx))):\n\u001b[0;32m--> 291\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    292\u001b[0m     data \u001b[38;5;241m=\u001b[39m data \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(data)\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/Playground/Python/GrapHIV/src/dataset.py:79\u001b[0m, in \u001b[0;36mMoleculeDataset.get\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     77\u001b[0m     data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessed_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_test_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 79\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocessed_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mindex\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/Playground/Python/GrapHIV/venv/lib/python3.10/site-packages/torch/serialization.py:1026\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1024\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1025\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1026\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1027\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1028\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[43m                     \u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverall_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1030\u001b[0m \u001b[43m                     \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1031\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n\u001b[1;32m   1032\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmmap can only be used with files saved with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1033\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`torch.save(_use_new_zipfile_serialization=True), \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1034\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplease torch.save your checkpoint with this option in order to use mmap.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Playground/Python/GrapHIV/venv/lib/python3.10/site-packages/torch/serialization.py:1438\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1436\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(data_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1437\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[0;32m-> 1438\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1440\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m   1441\u001b[0m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_log_api_usage_metadata(\n\u001b[1;32m   1442\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.load.metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mserialization_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: zip_file\u001b[38;5;241m.\u001b[39mserialization_id()}\n\u001b[1;32m   1443\u001b[0m )\n",
      "File \u001b[0;32m~/Playground/Python/GrapHIV/venv/lib/python3.10/site-packages/torch/serialization.py:1408\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1407\u001b[0m     nbytes \u001b[38;5;241m=\u001b[39m numel \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_element_size(dtype)\n\u001b[0;32m-> 1408\u001b[0m     typed_storage \u001b[38;5;241m=\u001b[39m \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1410\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m typed_storage\n",
      "File \u001b[0;32m~/Playground/Python/GrapHIV/venv/lib/python3.10/site-packages/torch/serialization.py:1382\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1377\u001b[0m         storage\u001b[38;5;241m.\u001b[39mbyteswap(dtype)\n\u001b[1;32m   1379\u001b[0m \u001b[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[1;32m   1380\u001b[0m \u001b[38;5;66;03m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[1;32m   1381\u001b[0m typed_storage \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39mTypedStorage(\n\u001b[0;32m-> 1382\u001b[0m     wrap_storage\u001b[38;5;241m=\u001b[39m\u001b[43mrestore_location\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1383\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m   1384\u001b[0m     _internal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1386\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typed_storage\u001b[38;5;241m.\u001b[39m_data_ptr() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1387\u001b[0m     loaded_storages[key] \u001b[38;5;241m=\u001b[39m typed_storage\n",
      "File \u001b[0;32m~/Playground/Python/GrapHIV/venv/lib/python3.10/site-packages/torch/serialization.py:389\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m location\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdon\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt know how to determine data location of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    386\u001b[0m                        \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39mtypename(storage))\n\u001b[0;32m--> 389\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_restore_location\u001b[39m(storage, location):\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, _, fn \u001b[38;5;129;01min\u001b[39;00m _package_registry:\n\u001b[1;32m    391\u001b[0m         result \u001b[38;5;241m=\u001b[39m fn(storage, location)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Running Hyperparameter search: \")\n",
    "config = dict()\n",
    "config[\"optimizer\"] = \"Bayesian\"\n",
    "config[\"num_iteration\"] = 100\n",
    "\n",
    "tuner = Tuner(HYPERPARAMETERS, objective=run_one_training, conf_dict=config)\n",
    "results = tuner.minimize()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
